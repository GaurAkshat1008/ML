{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "VOCAB_SIZE = 88584\n",
    "\n",
    "MAXLEN = 250\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 22665,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 21631,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 19193,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 10311,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 31050,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 12118,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.keras.preprocessing.sequence.pad_sequences(train_data, maxlen=MAXLEN)\n",
    "test_data = tf.keras.preprocessing.sequence.pad_sequences(test_data, maxlen=MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     1,    14,    22,    16,\n",
       "          43,   530,   973,  1622,  1385,    65,   458,  4468,    66,\n",
       "        3941,     4,   173,    36,   256,     5,    25,   100,    43,\n",
       "         838,   112,    50,   670, 22665,     9,    35,   480,   284,\n",
       "           5,   150,     4,   172,   112,   167, 21631,   336,   385,\n",
       "          39,     4,   172,  4536,  1111,    17,   546,    38,    13,\n",
       "         447,     4,   192,    50,    16,     6,   147,  2025,    19,\n",
       "          14,    22,     4,  1920,  4613,   469,     4,    22,    71,\n",
       "          87,    12,    16,    43,   530,    38,    76,    15,    13,\n",
       "        1247,     4,    22,    17,   515,    17,    12,    16,   626,\n",
       "          18, 19193,     5,    62,   386,    12,     8,   316,     8,\n",
       "         106,     5,     4,  2223,  5244,    16,   480,    66,  3785,\n",
       "          33,     4,   130,    12,    16,    38,   619,     5,    25,\n",
       "         124,    51,    36,   135,    48,    25,  1415,    33,     6,\n",
       "          22,    12,   215,    28,    77,    52,     5,    14,   407,\n",
       "          16,    82, 10311,     8,     4,   107,   117,  5952,    15,\n",
       "         256,     4, 31050,     7,  3766,     5,   723,    36,    71,\n",
       "          43,   530,   476,    26,   400,   317,    46,     7,     4,\n",
       "       12118,  1029,    13,   104,    88,     4,   381,    15,   297,\n",
       "          98,    32,  2071,    56,    26,   141,     6,   194,  7486,\n",
       "          18,     4,   226,    22,    21,   134,   476,    26,   480,\n",
       "           5,   144,    30,  5535,    18,    51,    36,    28,   224,\n",
       "          92,    25,   104,     4,   226,    65,    16,    38,  1334,\n",
       "          88,    12,    16,   283,     5,    16,  4472,   113,   103,\n",
       "          32,    15,    16,  5345,    19,   178,    32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
    "  tf.keras.layers.LSTM(32),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          2834688   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                8320      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,843,041\n",
      "Trainable params: 2,843,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 51s 77ms/step - loss: 0.4155 - accuracy: 0.8078 - val_loss: 0.5069 - val_accuracy: 0.8068\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 78s 125ms/step - loss: 0.2396 - accuracy: 0.9100 - val_loss: 0.2851 - val_accuracy: 0.8834\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 63s 101ms/step - loss: 0.1836 - accuracy: 0.9329 - val_loss: 0.2906 - val_accuracy: 0.8858\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 77s 123ms/step - loss: 0.1507 - accuracy: 0.9466 - val_loss: 0.2808 - val_accuracy: 0.8996\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 66s 105ms/step - loss: 0.1249 - accuracy: 0.9562 - val_loss: 0.2965 - val_accuracy: 0.8806\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 63s 100ms/step - loss: 0.1084 - accuracy: 0.9630 - val_loss: 0.3659 - val_accuracy: 0.8814\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 60s 96ms/step - loss: 0.0949 - accuracy: 0.9690 - val_loss: 0.3108 - val_accuracy: 0.8892\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 65s 104ms/step - loss: 0.0833 - accuracy: 0.9714 - val_loss: 0.3507 - val_accuracy: 0.8882\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 85s 137ms/step - loss: 0.0753 - accuracy: 0.9751 - val_loss: 0.3264 - val_accuracy: 0.8932\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 59s 95ms/step - loss: 0.0650 - accuracy: 0.9789 - val_loss: 0.4555 - val_accuracy: 0.8806\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(train_data, train_labels, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"imdb_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(\"imdb_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 22s 27ms/step - loss: 0.5941 - accuracy: 0.8461\n"
     ]
    }
   ],
   "source": [
    "results = new_model.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5940593481063843, 0.8461199998855591]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "\n",
    "def encode_text(text):\n",
    "  tokens = tf.keras.preprocessing.text.text_to_word_sequence(text)\n",
    "  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
    "  return tf.keras.preprocessing.sequence.pad_sequences([tokens], MAXLEN)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  10  63 420  11  17   9  13   3  84  17]\n"
     ]
    }
   ],
   "source": [
    "text = \"I really liked this movie. It was a great movie.\"\n",
    "encoded = encode_text(text)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
    "\n",
    "def decode_integers(integers):\n",
    "    PAD = 0\n",
    "    text = \"\"\n",
    "    for num in integers:\n",
    "      if num != PAD:\n",
    "        text += reverse_word_index[num] + \" \"\n",
    "\n",
    "    return text[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i really liked this movie it was a great movie\n"
     ]
    }
   ],
   "source": [
    "print(decode_integers(encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "  encoded_text = encode_text(text)\n",
    "  pred = np.zeros((1, 250))\n",
    "  pred[0] = encoded_text\n",
    "  result = new_model.predict(pred)\n",
    "  print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_review = \"That movie was! really loved it and would great watch it again because it was amazingly great\"\n",
    "negative_review = \"that movie really hated. I hated it and would watch it again. Was one of the worst things I've ever watched\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(predict(positive_review))\n",
    "(predict(negative_review))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16cbfd488c5975e37383eb0f188994446250960114289268028bdee6c9f52fe2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
